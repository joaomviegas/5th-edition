{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome\n",
    "\n",
    "In this exercises notebook you are going to do another small hackathon. The dataset is in `data`. You have to unzip the file and look for the `propublica_data_for_fairml.csv` file. \n",
    "\n",
    "Your objective is to train an ML model on this data, and then apply what you've learned in this unit about Bias and Fairness and use the python toolkit [Aequitas](https://github.com/dssg/aequitas) to analyze your ML model's fairness.\n",
    "\n",
    "# Dataset Overview - COMPAS Recidivism Racial Bias\n",
    "\n",
    "COMPAS (Correctional Offender Management Profiling for Alternative Sanctions) is a popular commercial algorithm used by judges and parole officers for scoring criminal defendantâ€™s likelihood of reoffending (recidivism). It has been shown that the algorithm is biased in favor of white defendants, and against black inmates, based on a 2 year follow up study (i.e who actually committed crimes or violent crimes after 2 years). The pattern of mistakes, as measured by precision/sensitivity is notable.\n",
    "\n",
    "\n",
    "Data contains variables used by the COMPAS algorithm in scoring defendants, along with their outcomes within 2 years of the decision, for over 10,000 criminal defendants in Broward County, Florida.\n",
    "\n",
    "3 subsets of the data are provided, including a subset of only violent recividism (as opposed to, e.g. being reincarcerated for non violent offenses such as vagrancy or Marijuana).\n",
    "\n",
    "# Objectives\n",
    "\n",
    "1. Read and clean the data\n",
    "2. Perform Exploratory Data Analysis to understand the data \n",
    "    1. What are the sensitive attributes of this dataset? \n",
    "    2. What is the age distribution? \n",
    "    3. What is the etnicity distribution and prevalence on each group?\n",
    "3. Fit a logistic regression with the default parameters and summarize the model's performance on a validation set (precision, recall, f1)\n",
    "5. **Most Important** Use Aequitas to analyze potential biases your model might have. You have here the freedom to explore the Aequitas tool hands-on and provide interesting fairness analyses.\n",
    "6. (if you still have remaining time) perform hyperparameter optimization through cross validation with a Random Forest and obtain a model that performs better than your Logistic regression.\n",
    "7. Redo your fairness analysis and report any major differences in fairness that you found between the two models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
